{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM_Word2Vec_Classification.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMNZnHrw4deYN8/2z8uyqvD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zxarda01/Tweet-Sentiment-Classification-/blob/main/SVM_Word2Vec_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T053aopEXwG9",
        "outputId": "326629d6-35d4-4e86-da3d-e9c2e2ab1297"
      },
      "source": [
        "# Data Preparation\r\n",
        "!wget https://raw.githubusercontent.com/whyjay17/Twitter-Sentiment-Analysis/master/data/twitter-2016dev-A.txt\r\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-02 03:36:43--  https://raw.githubusercontent.com/whyjay17/Twitter-Sentiment-Analysis/master/data/twitter-2016dev-A.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 294054 (287K) [text/plain]\n",
            "Saving to: ‘twitter-2016dev-A.txt.1’\n",
            "\n",
            "\rtwitter-2016dev-A.t   0%[                    ]       0  --.-KB/s               \rtwitter-2016dev-A.t 100%[===================>] 287.16K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-01-02 03:36:43 (7.27 MB/s) - ‘twitter-2016dev-A.txt.1’ saved [294054/294054]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8G5XGfcZx_1",
        "outputId": "9fb061a1-efb6-4044-ec08-a77000d9faf0"
      },
      "source": [
        "!wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-02 03:36:43--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.12.246\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.12.246|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuOar6-5aX0P",
        "outputId": "79947ae9-951f-4216-a55e-6a6b59ff7842"
      },
      "source": [
        "# Package Installation\r\n",
        "!pip install scikit-learn\r\n",
        "!pip install nltk\r\n",
        "!pip install numpy\r\n",
        "!pip install gensim\r\n",
        "\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.0.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.19.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.19.4)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.19.4)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (4.0.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.15.0)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5Eq83UTmNV8",
        "outputId": "5f624f10-99b1-4c55-cfdc-5ad083220443"
      },
      "source": [
        "# Data Loading\r\n",
        "import csv\r\n",
        "import string\r\n",
        "import numpy as np\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.tokenize import TweetTokenizer\r\n",
        "from gensim.models.keyedvectors import KeyedVectors\r\n",
        "\r\n",
        "tweet_data_path = '/content/twitter-2016dev-A.txt'\r\n",
        "word2vec_path = '/content/GoogleNews-vectors-negative300.bin.gz'\r\n",
        "tweet_tokenizer = TweetTokenizer()\r\n",
        "\r\n",
        "with open(tweet_data_path , encoding='utf-8') as f:\r\n",
        "    reader = csv.reader(f, delimiter=\"\\t\")\r\n",
        "    tweet_data = list(reader)\r\n",
        "\r\n",
        "\r\n",
        "print('[input]# of records:',len(tweet_data))\r\n",
        "print('[input]sample data:',tweet_data[0])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[input]# of records: 1966\n",
            "[input]sample data: ['638060586258038784', 'neutral', '05 Beat it - Michael Jackson - Thriller (25th Anniversary Edition) [HD] http://t.co/A4K2B86PBv']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDSEvJHtbo3R",
        "outputId": "3ae2af3c-68f8-41e1-e825-6ca22c9f7fc7"
      },
      "source": [
        "# Data Preprocessing\r\n",
        "tweet_data_parsed = []\r\n",
        "stop = set(stopwords.words('english'))\r\n",
        "for info in tweet_data:\r\n",
        "    l = \" \".join(tweet_tokenizer.tokenize(info[2].lower())).split(\" \")\r\n",
        "    filtered_sentence = [w for w in l if not w in stop and not w in string.punctuation\r\n",
        "                         and ( w[0] != '@' and w[0] != '#' and w[:4] != 'http' )]\r\n",
        "    tweet_data_parsed.append(filtered_sentence)\r\n",
        "\r\n",
        "print('[parsed]# of records:',len(tweet_data_parsed))\r\n",
        "print('[parsed]sample data:',tweet_data_parsed[0])\r\n",
        "\r\n",
        "# Label Data\r\n",
        "tweet_class = np.zeros(len(tweet_data))\r\n",
        "for i in range(len(tweet_data)):\r\n",
        "    if tweet_data[i][1] == 'negative':\r\n",
        "        tweet_class[i] = 0\r\n",
        "    elif tweet_data[i][1] == 'neutral':\r\n",
        "        tweet_class[i] = 1\r\n",
        "    elif tweet_data[i][1] == 'positive':\r\n",
        "        tweet_class[i] = 2\r\n",
        "\r\n",
        "print('[class]# of records:',len(tweet_class))\r\n",
        "print('[class]sample data:',tweet_class[0])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[parsed]# of records: 1966\n",
            "[parsed]sample data: ['05', 'beat', 'michael', 'jackson', 'thriller', '25th', 'anniversary', 'edition', 'hd']\n",
            "[class]# of records: 1966\n",
            "[class]sample data: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JL6znv22iVeH",
        "outputId": "fba12049-0de9-4a20-f7a4-f453f05c6241"
      },
      "source": [
        "print('Model Loading Started')\r\n",
        "model = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)\r\n",
        "print('Model Loading Finished')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Loading Started\n",
            "Model Loading Finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykuL8LLHgDh5",
        "outputId": "54541362-3dd5-4b5c-accd-7109ad8adff3"
      },
      "source": [
        "# Feature(word2vec) \r\n",
        "tweet_word2vec = []\r\n",
        "# adds the word2vec average\r\n",
        "for tweet in tweet_data_parsed:\r\n",
        "    average_vec = np.zeros(300)\r\n",
        "    for word in tweet:\r\n",
        "        if word in model.wv:\r\n",
        "            average_vec += (model.wv[word] / len(tweet))\r\n",
        "        else:\r\n",
        "            pass\r\n",
        "    tweet_word2vec.append(average_vec)\r\n",
        "\r\n",
        "# train test split\r\n",
        "ratio = len(tweet_data) * 0.2\r\n",
        "tweet_train = tweet_data_parsed[: -int(ratio)]\r\n",
        "tweet_test = tweet_data_parsed[-int(ratio):]\r\n",
        "\r\n",
        "x_train = tweet_word2vec[: -int(ratio)]\r\n",
        "y_train = tweet_class[: -int(ratio)]\r\n",
        "\r\n",
        "x_test = tweet_word2vec[-int(ratio):]\r\n",
        "y_test = tweet_class[-int(ratio):]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8G5NXKodtN6J",
        "outputId": "049b1b8c-d9f3-4c56-a5fe-0b60237b99e8"
      },
      "source": [
        "import time\r\n",
        "from sklearn.svm import LinearSVC\r\n",
        "from sklearn.model_selection import GridSearchCV \r\n",
        "from sklearn import preprocessing\r\n",
        "\r\n",
        "x_train = preprocessing.scale(x_train)\r\n",
        "\r\n",
        "\r\n",
        "print(\"started\") \r\n",
        "start = time.time()\r\n",
        "param_grid = {'C': [0.1,1] } \r\n",
        "clf = GridSearchCV(LinearSVC(max_iter = 50000), param_grid, refit = True, verbose = 3) \r\n",
        "clf.fit(x_train,y_train)\r\n",
        "end = time.time()\r\n",
        "print(\"finished\")\r\n",
        "print(\"duration\", end-start)\r\n",
        "\r\n",
        "result1 = clf.predict(x_test)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "started\n",
            "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
            "[CV] C=0.1 ...........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............................... C=0.1, score=0.498, total=   4.6s\n",
            "[CV] C=0.1 ...........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............................... C=0.1, score=0.416, total=   3.7s\n",
            "[CV] C=0.1 ...........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    8.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............................... C=0.1, score=0.416, total=   4.8s\n",
            "[CV] C=0.1 ...........................................................\n",
            "[CV] ............................... C=0.1, score=0.411, total=   4.9s\n",
            "[CV] C=0.1 ...........................................................\n",
            "[CV] ............................... C=0.1, score=0.433, total=   4.5s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ................................. C=1, score=0.483, total=  50.8s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ................................. C=1, score=0.413, total=  36.1s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ................................. C=1, score=0.416, total=  45.8s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ................................. C=1, score=0.395, total=  55.7s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ................................. C=1, score=0.424, total=  46.9s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  4.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "finished\n",
            "duration 264.55963802337646\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0B799e7NIl3",
        "outputId": "1c6cc7fd-99bb-4b19-89dd-928f5a4509be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def cal_precision_recall(y, pred) :\r\n",
        "  cnf_matrix = confusion_matrix(y, pred)\r\n",
        "  print(cnf_matrix)\r\n",
        "  \r\n",
        "  recall = np.diag(cnf_matrix) / np.sum(cnf_matrix, axis = 1)  \r\n",
        "  avg_recall = np.mean(recall)\r\n",
        "  print(\"avg_recall\",avg_recall)\r\n",
        "\r\n",
        "cal_precision_recall(y_test,result1)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0  30  41]\n",
            " [  0  51  99]\n",
            " [  0  19 153]]\n",
            "avg_recall 0.4098449612403101\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}