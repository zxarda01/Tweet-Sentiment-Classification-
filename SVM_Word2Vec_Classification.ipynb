{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM_Word2Vec_Classification.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPPSwrjMMTSbQWrDLC8jacS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zxarda01/Tweet-Sentiment-Classification-/blob/main/SVM_Word2Vec_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T053aopEXwG9",
        "outputId": "d9d0e95e-5d72-4067-9bbe-db718106f946"
      },
      "source": [
        "# Data Preparation\r\n",
        "!wget https://raw.githubusercontent.com/whyjay17/Twitter-Sentiment-Analysis/master/data/twitter-2016dev-A.txt\r\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-02 03:03:36--  https://raw.githubusercontent.com/whyjay17/Twitter-Sentiment-Analysis/master/data/twitter-2016dev-A.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 294054 (287K) [text/plain]\n",
            "Saving to: ‘twitter-2016dev-A.txt’\n",
            "\n",
            "twitter-2016dev-A.t 100%[===================>] 287.16K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-01-02 03:03:36 (7.33 MB/s) - ‘twitter-2016dev-A.txt’ saved [294054/294054]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8G5XGfcZx_1",
        "outputId": "66ad568d-0320-45f0-a30c-0ad937b7438e"
      },
      "source": [
        "!wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-02 03:03:38--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.82.70\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.82.70|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  73.1MB/s    in 24s     \n",
            "\n",
            "2021-01-02 03:04:02 (64.6 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuOar6-5aX0P",
        "outputId": "2fcc5b71-9a62-406e-dbe6-0b6ae70ab568"
      },
      "source": [
        "# Package Installation\r\n",
        "!pip install scikit-learn\r\n",
        "!pip install nltk\r\n",
        "!pip install numpy\r\n",
        "!pip install gensim\r\n",
        "\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.19.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.0.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.19.4)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.19.4)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (4.0.1)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5Eq83UTmNV8",
        "outputId": "22c35a35-e932-4895-9744-b6142e200f08"
      },
      "source": [
        "# Data Loading\r\n",
        "import csv\r\n",
        "import string\r\n",
        "import numpy as np\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.tokenize import TweetTokenizer\r\n",
        "from gensim.models.keyedvectors import KeyedVectors\r\n",
        "\r\n",
        "tweet_data_path = '/content/twitter-2016dev-A.txt'\r\n",
        "word2vec_path = '/content/GoogleNews-vectors-negative300.bin.gz'\r\n",
        "tweet_tokenizer = TweetTokenizer()\r\n",
        "\r\n",
        "with open(tweet_data_path , encoding='utf-8') as f:\r\n",
        "    reader = csv.reader(f, delimiter=\"\\t\")\r\n",
        "    tweet_data = list(reader)\r\n",
        "\r\n",
        "\r\n",
        "print('[input]# of records:',len(tweet_data))\r\n",
        "print('[input]sample data:',tweet_data[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[input]# of records: 1966\n",
            "[input]sample data: ['638060586258038784', 'neutral', '05 Beat it - Michael Jackson - Thriller (25th Anniversary Edition) [HD] http://t.co/A4K2B86PBv']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDSEvJHtbo3R",
        "outputId": "3b946821-cb9d-48d7-b801-9ff003051ab5"
      },
      "source": [
        "# Data Preprocessing\r\n",
        "tweet_data_parsed = []\r\n",
        "stop = set(stopwords.words('english'))\r\n",
        "for info in tweet_data:\r\n",
        "    l = \" \".join(tweet_tokenizer.tokenize(info[2].lower())).split(\" \")\r\n",
        "    filtered_sentence = [w for w in l if not w in stop and not w in string.punctuation\r\n",
        "                         and ( w[0] != '@' and w[0] != '#' and w[:4] != 'http' )]\r\n",
        "    tweet_data_parsed.append(filtered_sentence)\r\n",
        "\r\n",
        "print('[parsed]# of records:',len(tweet_data_parsed))\r\n",
        "print('[parsed]sample data:',tweet_data_parsed[0])\r\n",
        "\r\n",
        "# Label Data\r\n",
        "tweet_class = np.zeros(len(tweet_data))\r\n",
        "for i in range(len(tweet_data)):\r\n",
        "    if tweet_data[i][1] == 'negative':\r\n",
        "        tweet_class[i] = 0\r\n",
        "    elif tweet_data[i][1] == 'neutral':\r\n",
        "        tweet_class[i] = 1\r\n",
        "    elif tweet_data[i][1] == 'positive':\r\n",
        "        tweet_class[i] = 2\r\n",
        "\r\n",
        "print('[class]# of records:',len(tweet_class))\r\n",
        "print('[class]sample data:',tweet_class[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[parsed]# of records: 1966\n",
            "[parsed]sample data: ['05', 'beat', 'michael', 'jackson', 'thriller', '25th', 'anniversary', 'edition', 'hd']\n",
            "[class]# of records: 1966\n",
            "[class]sample data: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JL6znv22iVeH",
        "outputId": "f4879f5c-825a-4ac6-9b46-64e472d61799"
      },
      "source": [
        "print('Model Loading Started')\r\n",
        "model = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)\r\n",
        "print('Model Loading Finished')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Loading Started\n",
            "Model Loading Finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykuL8LLHgDh5",
        "outputId": "c50d3758-0893-48fb-8608-fed600db2635"
      },
      "source": [
        "# Feature(word2vec) \r\n",
        "tweet_word2vec = []\r\n",
        "# adds the word2vec average\r\n",
        "for tweet in tweet_data_parsed:\r\n",
        "    average_vec = np.zeros(300)\r\n",
        "    for word in tweet:\r\n",
        "        if word in model.wv:\r\n",
        "            average_vec += (model.wv[word] / len(tweet))\r\n",
        "        else:\r\n",
        "            pass\r\n",
        "    tweet_word2vec.append(average_vec)\r\n",
        "\r\n",
        "# train test split\r\n",
        "ratio = len(tweet_data) * 0.2\r\n",
        "tweet_train = tweet_data_parsed[: -int(ratio)]\r\n",
        "tweet_test = tweet_data_parsed[-int(ratio):]\r\n",
        "\r\n",
        "x_train = tweet_word2vec[: -int(ratio)]\r\n",
        "y_train = tweet_class[: -int(ratio)]\r\n",
        "\r\n",
        "x_test = tweet_word2vec[-int(ratio):]\r\n",
        "y_test = tweet_class[-int(ratio):]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8G5NXKodtN6J",
        "outputId": "52131179-3af5-45e4-b555-8a47958ee47e"
      },
      "source": [
        "import time\r\n",
        "from sklearn.svm import LinearSVC\r\n",
        "from sklearn.model_selection import GridSearchCV \r\n",
        "from sklearn import preprocessing\r\n",
        "\r\n",
        "x_train = preprocessing.scale(x_train)\r\n",
        "\r\n",
        "\r\n",
        "print(\"started\") \r\n",
        "start = time.time()\r\n",
        "\r\n",
        "param_grid = {'C': [0.1,1,10] } \r\n",
        "clf = GridSearchCV(LinearSVC(max_iter = 50000), param_grid, refit = True, verbose = 3) \r\n",
        "clf.fit(x_train,y_train)\r\n",
        "\r\n",
        "end = time.time()\r\n",
        "print(\"finished\")\r\n",
        "print(\"duration\", end-start)\r\n",
        "result1 = clf.predict(x_test)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "started\n",
            "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
            "[CV] C=0.1 ...........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............................... C=0.1, score=0.498, total=   4.3s\n",
            "[CV] C=0.1 ...........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............................... C=0.1, score=0.416, total=   3.8s\n",
            "[CV] C=0.1 ...........................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    8.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ............................... C=0.1, score=0.416, total=   4.9s\n",
            "[CV] C=0.1 ...........................................................\n",
            "[CV] ............................... C=0.1, score=0.411, total=   4.6s\n",
            "[CV] C=0.1 ...........................................................\n",
            "[CV] ............................... C=0.1, score=0.433, total=   3.8s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ................................. C=1, score=0.483, total=  48.7s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ................................. C=1, score=0.413, total=  39.2s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ................................. C=1, score=0.416, total=  47.2s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ................................. C=1, score=0.395, total=  55.0s\n",
            "[CV] C=1 .............................................................\n",
            "[CV] ................................. C=1, score=0.424, total=  46.9s\n",
            "[CV] C=10 ............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................ C=10, score=0.489, total= 1.8min\n",
            "[CV] C=10 ............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................ C=10, score=0.413, total= 1.7min\n",
            "[CV] C=10 ............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................ C=10, score=0.419, total= 1.7min\n",
            "[CV] C=10 ............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................ C=10, score=0.395, total= 1.7min\n",
            "[CV] C=10 ............................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 12.9min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................................ C=10, score=0.427, total= 1.8min\n",
            "finished\n",
            "duration 780.9675941467285\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oXpp1jgFIzf",
        "outputId": "3ed46450-2f14-4d63-97d6-63fa49be6f3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "\r\n",
        "def cal_precision_recall(y, pred) :\r\n",
        "\r\n",
        "    cnf_matrix = confusion_matrix(y, pred)\r\n",
        "    print(cnf_matrix)\r\n",
        "\r\n",
        "    recall = np.diag(cnf_matrix) / np.sum(cnf_matrix, axis = 1)\r\n",
        "    precision = np.diag(cnf_matrix) / np.sum(cnf_matrix, axis = 0)\r\n",
        "\r\n",
        "    avg_recall = np.mean(recall)\r\n",
        "    avg_precision = np.mean(precision)\r\n",
        "\r\n",
        "    print(\"avg_recall\",avg_recall)\r\n",
        "    print(\"avg_precision\",avg_precision)\r\n",
        "pred = clf.predict(x_test)\r\n",
        "cal_precision_recall(y_test,pred)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0  30  41]\n",
            " [  0  51  99]\n",
            " [  0  19 153]]\n",
            "avg_recall 0.4098449612403101\n",
            "avg_precision nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in true_divide\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}