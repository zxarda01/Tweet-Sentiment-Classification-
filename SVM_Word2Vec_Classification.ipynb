{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM_Word2Vec_Classification.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM3VMkfOfIC+DYLnfVLYNlR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zxarda01/Tweet-Sentiment-Classification-/blob/main/SVM_Word2Vec_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T053aopEXwG9",
        "outputId": "c2a5c3cc-3315-49b7-a890-59e7e78c782c"
      },
      "source": [
        "# Data Preparation\r\n",
        "!wget https://raw.githubusercontent.com/whyjay17/Twitter-Sentiment-Analysis/master/data/twitter-2016dev-A.txt\r\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-29 17:13:40--  https://raw.githubusercontent.com/whyjay17/Twitter-Sentiment-Analysis/master/data/twitter-2016dev-A.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 294054 (287K) [text/plain]\n",
            "Saving to: ‘twitter-2016dev-A.txt’\n",
            "\n",
            "twitter-2016dev-A.t 100%[===================>] 287.16K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-12-29 17:13:41 (7.34 MB/s) - ‘twitter-2016dev-A.txt’ saved [294054/294054]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8G5XGfcZx_1",
        "outputId": "fbadab3b-abd0-49e3-9369-3543bd6cae55"
      },
      "source": [
        "!wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-29 17:13:45--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.228.115\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.228.115|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  16.9MB/s    in 95s     \n",
            "\n",
            "2020-12-29 17:15:20 (16.6 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuOar6-5aX0P",
        "outputId": "3b0fd2c7-3b6a-4521-b316-c9a2579b8f9e"
      },
      "source": [
        "# Package Installation\r\n",
        "!pip install scikit-learn\r\n",
        "!pip install nltk\r\n",
        "!pip install numpy\r\n",
        "!pip gensim\r\n",
        "\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.0.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.19.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.19.4)\n",
            "ERROR: unknown command \"gensim\"\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5Eq83UTmNV8",
        "outputId": "308b71b2-df77-44b9-acd1-cfefa4d696f3"
      },
      "source": [
        "# Data Loading\r\n",
        "import csv\r\n",
        "import string\r\n",
        "import numpy as np\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.tokenize import TweetTokenizer\r\n",
        "from gensim.models.keyedvectors import KeyedVectors\r\n",
        "\r\n",
        "tweet_data_path = '/content/twitter-2016dev-A.txt'\r\n",
        "word2vec_path = '/content/GoogleNews-vectors-negative300.bin.gz'\r\n",
        "tweet_tokenizer = TweetTokenizer()\r\n",
        "\r\n",
        "with open(tweet_data_path , encoding='utf-8') as f:\r\n",
        "    reader = csv.reader(f, delimiter=\"\\t\")\r\n",
        "    tweet_data = list(reader)\r\n",
        "\r\n",
        "\r\n",
        "print('[input]# of records:',len(tweet_data))\r\n",
        "print('[input]sample data:',tweet_data[0])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[input]# of records: 1966\n",
            "[input]sample data: ['638060586258038784', 'neutral', '05 Beat it - Michael Jackson - Thriller (25th Anniversary Edition) [HD] http://t.co/A4K2B86PBv']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDSEvJHtbo3R",
        "outputId": "531a1290-1942-441c-a045-0afdc2b6bd69"
      },
      "source": [
        "# Data Preprocessing\r\n",
        "tweet_data_parsed = []\r\n",
        "stop = set(stopwords.words('english'))\r\n",
        "for info in tweet_data:\r\n",
        "    l = \" \".join(tweet_tokenizer.tokenize(info[2].lower())).split(\" \")\r\n",
        "    filtered_sentence = [w for w in l if not w in stop and not w in string.punctuation\r\n",
        "                         and ( w[0] != '@' and w[0] != '#' and w[:4] != 'http' )]\r\n",
        "    tweet_data_parsed.append(filtered_sentence)\r\n",
        "\r\n",
        "print('[parsed]# of records:',len(tweet_data_parsed))\r\n",
        "print('[parsed]sample data:',tweet_data_parsed[0])\r\n",
        "\r\n",
        "# Label Data\r\n",
        "tweet_class = np.zeros(len(tweet_data))\r\n",
        "for i in range(len(tweet_data)):\r\n",
        "    if tweet_data[i][1] == 'negative':\r\n",
        "        tweet_class[i] = 0\r\n",
        "    elif tweet_data[i][1] == 'neutral':\r\n",
        "        tweet_class[i] = 1\r\n",
        "    elif tweet_data[i][1] == 'positive':\r\n",
        "        tweet_class[i] = 2\r\n",
        "\r\n",
        "print('[class]# of records:',len(tweet_class))\r\n",
        "print('[class]sample data:',tweet_class[0])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[parsed]# of records: 1966\n",
            "[parsed]sample data: ['05', 'beat', 'michael', 'jackson', 'thriller', '25th', 'anniversary', 'edition', 'hd']\n",
            "[class]# of records: 1966\n",
            "[class]sample data: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JL6znv22iVeH",
        "outputId": "87c04988-bcdd-4d31-8656-7adcbd9304de"
      },
      "source": [
        "print('Model Loading Started')\r\n",
        "model = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)\r\n",
        "print('Model Loading Finished')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "started\n",
            "finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykuL8LLHgDh5",
        "outputId": "48488880-cdb5-4439-d665-12fe789ad71a"
      },
      "source": [
        "# Feature(word2vec) \r\n",
        "tweet_word2vec = []\r\n",
        "# adds the word2vec average\r\n",
        "for tweet in tweet_data_parsed:\r\n",
        "    average_vec = np.zeros(300)\r\n",
        "    for word in tweet:\r\n",
        "        if word in model.wv:\r\n",
        "            average_vec += (model.wv[word] / len(tweet))\r\n",
        "        else:\r\n",
        "            pass\r\n",
        "    tweet_word2vec.append(average_vec)\r\n",
        "\r\n",
        "# train test split\r\n",
        "ratio = len(tweet_data) * 0.2\r\n",
        "tweet_train = tweet_data_parsed[: -int(ratio)]\r\n",
        "tweet_test = tweet_data_parsed[-int(ratio):]\r\n",
        "\r\n",
        "x_train = tweet_word2vec[: -int(ratio)]\r\n",
        "y_train = tweet_class[: -int(ratio)]\r\n",
        "\r\n",
        "x_test = tweet_word2vec[-int(ratio):]\r\n",
        "y_test = tweet_class[-int(ratio):]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8G5NXKodtN6J",
        "outputId": "f22e7dec-0ec9-4ebf-c251-5e524222f112"
      },
      "source": [
        "from sklearn import preprocessing\r\n",
        "x_train = preprocessing.scale(x_train)\r\n",
        "\r\n",
        "# Train SVM\r\n",
        "from sklearn import svm\r\n",
        "\r\n",
        "print(\"started\") \r\n",
        "\r\n",
        "import time\r\n",
        "start = time.time()\r\n",
        "clf = svm.SVC(decision_function_shape='ovo', verbose=True)\r\n",
        "clf.fit(x_train, y_train)\r\n",
        "#svm.SVC(decision_function_shape='ovo')\r\n",
        "\r\n",
        "print(\"finished\")\r\n",
        "result1 = clf.predict(x_test)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "started\n",
            "[LibSVM]finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEE9pDl5g22w",
        "outputId": "04ef090a-606d-43b4-f48e-e6e96295f2ae"
      },
      "source": [
        "# evaluation\r\n",
        "\r\n",
        "fn_positive = 0\r\n",
        "tp_positive = 0\r\n",
        "\r\n",
        "for i, j in zip(y_test, result1):\r\n",
        "    if i == 2 and i != j:\r\n",
        "        fn_positive += 1\r\n",
        "    if i == 2 and i == j:\r\n",
        "        tp_positive += 1\r\n",
        "\r\n",
        "fn_neutral = 0\r\n",
        "tp_neutral = 0\r\n",
        "\r\n",
        "for i, j in zip(y_test, result1):\r\n",
        "    if (i == 1 and i != j):\r\n",
        "        fn_neutral += 1\r\n",
        "    if i == 1 and i == j:\r\n",
        "        tp_neutral += 1\r\n",
        "\r\n",
        "fn_negative = 0\r\n",
        "tp_negative = 0\r\n",
        "\r\n",
        "for i, j in zip(y_test, result1):\r\n",
        "    if (i == 0 and i != j):\r\n",
        "        fn_negative += 1\r\n",
        "    if i == 0 and i == j:\r\n",
        "        tp_negative += 1\r\n",
        "\r\n",
        "recall_pos = tp_positive / (tp_positive + fn_positive) if (tp_positive + fn_positive) != 0 else 0\r\n",
        "recall_neg = tp_negative / (tp_negative + fn_negative) if (tp_negative + fn_negative) != 0 else 0\r\n",
        "recall_neu = tp_neutral / (tp_neutral + fn_neutral) if (tp_neutral + fn_neutral) != 0 else 0\r\n",
        "\r\n",
        "print('Average Recall : ', (1/3) * (recall_neg + recall_neu + recall_pos))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Recall :  0.49250645994832043\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMf9FNgYhf_u",
        "outputId": "5511bdba-430c-4e45-ec75-36cb44cf9ee6"
      },
      "source": [
        "# SVM \r\n",
        "from sklearn.svm import LinearSVC\r\n",
        "\r\n",
        "svc_model = LinearSVC(verbose=1)\r\n",
        "svc_model.fit(x_train, y_train)\r\n",
        "result1 = svc_model.predict(x_test)\r\n",
        "\r\n",
        "print(len(x_train))\r\n",
        "print(len(y_train))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[LibLinear]1573\n",
            "1573\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}